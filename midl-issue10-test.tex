% Mimick forcing page number of the first page as happens in the proceedings
\def\startpage{11}

\documentclass{midl}

\usepackage{mwe}
\usepackage{soul}
\jmlrproceedings{MIDL}{Medical Imaging with Deep Learning}
\jmlryear{2021}

% Commands...
% --------------------
\newcommand{\EmbedSeg}{\mbox{\textsc{EmbedSeg}}\xspace}
\newcommand{\miniheadline}[1]{\noindent\textbf{#1.}}

\makeatletter
\DeclareRobustCommand\onedot{\futurelet\@let@token\@onedot}
\def\@onedot{\ifx\@let@token.\else.\null\fi\xspace}

\def\eg{\emph{e.g}\onedot} \def\Eg{\emph{E.g}\onedot}
\def\ie{\emph{i.e}\onedot} \def\Ie{\emph{I.e}\onedot}
\def\cf{\emph{c.f}\onedot} \def\Cf{\emph{C.f}\onedot}
\def\etc{\emph{etc}\onedot} \def\vs{\emph{vs}\onedot}
\def\wrt{w.r.t\onedot} 
\def\dof{d.o.f\onedot}
\def\etal{\emph{et~al}\onedot}
\makeatother

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\title[Embedding-based Instance Segmentation of Microscopy Images]{Embedding-based Instance Segmentation \\of Microscopy Images}

\midlauthor{
\Name{Manan Lalit \nametag{$^{1,2}$}} \Email{lalit@mpi-cbg.de}
\AND
\Name{Pavel Tomancak \nametag{$^{2,3}$}} \Email{tomancak@mpi-cbg.de}
 \AND
\Name{Florian Jug \nametag{$^{1,2,4}$}} \Email{jug@mpi-cbg.de} \\
\addr $^{1}$~Center for Systems Biology Dresden (CSBD)\\
\addr $^{2}$~Max Planck Institute of Molecular Cell Biology and Genetics\\
\addr $^{3}$~IT4Innovations, V\v{S}B - Technical University of Ostrava, Ostrava-Poruba, Czech Republic \\
\addr $^{4}$~Fondazione Human Technopole, Milano, Italy}


\begin{document}
\maketitle
\begin{abstract}
Automatic detection and segmentation of objects in microscopy images is important for many biological applications.
In the domain of natural images, and in particular in the context of city street scenes~\cite{Cordts2016Cityscapes}, embedding-based instance segmentation leads to high-quality results.
Inspired by this line of work, we introduce \EmbedSeg, an end-to-end trainable deep learning method based on the work by Neven~\etal~\cite{neven2019}. While their approach embeds each pixel to the centroid of any given instance, in \EmbedSeg, motivated by the complex shapes of biological objects, we propose to use the medoid instead.
Additionally we also make use of a test-time augmentation scheme~\cite{wang2019,stringer2020}, and show that both suggested modifications improve the instance segmentation performance on 2D biological microscopy datasets notably.
 Next, we extend the network architecture of \EmbedSeg to provide a novel, light weight 3D architecture. 
 We demonstrate that our 3D architecture and approach achieves competitive results in comparison to state-of-the-art methods on diverse and biologically relevant 3D microscopy datasets.
We also provide two new instance-annotated datasets for use by the community for bench-marking instance segmentation methods.
Lastly, we show that the overall pipeline has a small enough memory footprint to be used on many CUDA enabled laptop hardware.
Our open-source implementation is available at \url{github.com/juglab/EmbedSeg}.
\end{abstract}

\begin{keywords}
instance segmentation, spatial embeddings, test-time augmentation, deep learning
\end{keywords}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
\label{sec:intro}
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \vspace{-2.5mm}
Instance segmentation of microscopy images involves locating all desired biological structures (instances) of a certain class (\eg `cell', `nucleus', or `membrane') in an image, assigning them a unique label or id, and creating a mask that perfectly delineates their shape. 
For many reasons, obtaining accurate segmentations is important and has therefore received significant attention~\cite{mejering2012,caicedo2019_v2}.

In recent years, Deep Learning (DL) based approaches have proven to be extraordinarily capable of instance segmentation in biological microscopy data~\cite{moen2019, caicedo2019_v2}.
Such methods can be grouped into two fundamental approaches: \textit{Top-down} and \textit{bottom-up} methods. 
To give an example, Mask R-CNN~\cite{he2017}, the arguably most prominent top-down method, detects object instances via bounding-boxes, then performs an additional refinement step to produce a pixel-mask from multiple bounding-box detections.
Bottom-up methods, in contrast, are designed such that each pixel makes a prediction of either the object class it belongs to~\cite{ronneberger2015}, and/or the shape of the object instance it is part of~\cite{schmidt2018,neven2019,hirsch2020}. 
In a second phase, all methods need to consolidate their detections/predictions in order to obtain the final set of object instances.
Mask R-CNN~\cite{he2017} or Stardist~\cite{schmidt2018}, for example, avoid multiple detections of the same object by employing non-maximum suppression on an instance associated confidence score. 

Unlike in natural images, where most objects have either a vertical (trees, pedestrians) or horizontal (cars, buses) orientation, objects visible in biological images are arbitrarily aligned with respect to the image axes. Mask R-CNN, employing axis-aligned bounding boxes, tends to miss detections as a consequence. Stardist, while improving upon this shortcoming, assumes a star-convex prior on the individual object shapes and suffers when the star-convex shape assumption is not fulfilled. 
\figQualitative

Here we present \EmbedSeg, a variation of the inspiring work by Neven~\etal~\cite{neven2019}, who propose a very compact model for end-to-end instance segmentation in the natural image domain.
This method works such that each pixel predicts its \textit{spatial embedding}, \ie another pixel location in the vicinity of the centroid of the object instance that the respective pixel is part of. 
Additionally, the network learns an instance-specific clustering band-width, later used to cluster embedding pixels into object instances. 
The segmentation mask of an object is defined by all pixels that embedded themselves to the same cluster of embedding pixels.
An additional \textit{seediness score} for each pixel is predicted, indicating how likely it is for the respective pixel, and its associated clustering band-width, to represent one object instance. 
All this can be trained end-to-end to predict highly accurate instance segmentations in natural images of street scenes.

In this work we evaluate how well embedding-based instance segmentation works in the domain of biological microscopy images.
We first evaluate the method by Neven~\etal~\cite{neven2019} on three well known datasets and show that results are close to the state-of-the-art method for the respective dataset.
We then propose modifications of the method by Neven~\etal and show that they improve the performance notably (see Section~\ref{sec:results} and Table~\ref{tab:results}).
Finally, we provide a memory-efficient open-source implementation of \EmbedSeg and compare its memory footprint to other state-of-the-art methods.

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Approach}
\label{sec:method}
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\resultsFinal
\ablationResults
\vspace{-2.5mm}
%\miniheadline{Embedding-Based Methods} 
In the past few years, embedding-based methods have emerged in computer vision.
Newell~\etal~\cite{newell2017}, in the context of multiperson pose estimation, suggested a DL framework where each pixel predicts a \emph{tag} or \textit{embedding}. 
The proposed loss function encourages pairs of such tags to have similar values if the corresponding pixels belonged to the same object.
In the same year, Brabandere~\etal~\cite{brabandere2017} suggested a specific hinge-loss which lead to improved clustering during inference, \ie they propose to penalize close proximity of the mean embedding of different objects. 
Novotny~\etal~\cite{novotny2018} later showed that constructing dense pixel embeddings to separate objects is not possible with a fully convolutional setup.
Neven~\etal~\cite{neven2019} built on this work and suggested a new loss function which pulls spatial embeddings of pixels belonging to the same object closer together and simultaneously learns an instance-specific clustering bandwidth.
Their end-to-end approach is set up to maximise the intersection over union (IoU) of predicted instances.

%\miniheadline{Neven\etal in a Nutshell}
In a nutshell, using an ERF-Net~\cite{romera2018}, each pixel $x_i\in S_k$, in an object instance with label $k$, is trained to predict
$(i)$~an offset vector $o_i$ that embeds it to $e_i = x_i + o_i$, ideally coinciding with the centroid of the ground truth mask $S_k$,
$(ii)$~an uncertainty $\sigma_i$ that estimates the error of $e_i$ \wrt the centroid, and
$(iii)$~a \textit{seediness score} $s_i$ that expresses the likelihood that this pixel coincides with the centroid of $S_k$.
Interestingly, the loss terms that enable the training of these predicted values also ensures that the IoU of $S_k$ and the predicted instance segmentation is maximized.

Once trained, the following inference scheme performs the final instance segmentation:
$(i)$~Greedily pick from all (remaining) pixels the one with the highest predicted seediness score $s_i > s_{\text{min}}$.
$(ii)$~Collect all pixels which embed themselves at this location with a confidence value of at least $0.5$.
$(iii)$~Remove all above-mentioned pixels from the candidate list and re-iterate.
In this work we use  $s_{\text{min}}=0.9$.

While Neven~\etal~\cite{neven2019} uses the centroid as desired embedding location during training, we argue that this is not the optimal choice when object shapes are more complex. 
We reason that it is desirable to choose a point that minimizes the average distance to all pixels $x_i \in S_k$, \ie the \textit{geometric median} (GM).
Like the centroid, also the GM has the unfortunate property that it can lie outside of its defining object. 
Such object-external points are bad embedding points for two reasons:
$(i)$~the seediness score of such points will likely be very low and cause inferior results during inference, and
$(ii)$~multiple such points might fall very close to each other in dense regions.
Hence we propose to use the \textit{medoid} instead of the centroid during training.
The medoid pixel of the object instance $S_k$ is the one pixel of the object with the smallest average distance to all other pixels and is defined as
% \begin{equation}\label{eq:medoid}
$x_\text{medoid} = \argmin_{y \in S_k} \sum_{x \in S_k} ||x,y||_2$.
% \end{equation}

We further improve results by employing a test-time augmentation scheme~\cite{wang2019,stringer2020}. 
To this end, we 8-fold augment a given test image by rotating and flipping. 
The trained model is then run on these eight copies, the predictions back-transformed and averaged.

Next we briefly discuss the datasets we used, the baseline methods we compare to, and the results we obtain with baselines and \EmbedSeg.

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Experiments and Results}
\label{sec:results}
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
We measure the performance of \EmbedSeg and the method by Neven~\etal~\cite{neven2019} against several state-of-the-art baseline methods that have been developed for microscopy instance segmentation in biology.
To this end, we tested all methods on three publicly available datasets, namely the \emph{BBBC010}~\cite{ljosa2012} \textit{C. elegans} brightfield dataset, the \emph{Usiigaci}~\cite{tsai2019} NIH/3T3 phase-contrast dataset, and the \emph{DSB}~\cite{caicedo2019} data from the Kaggle Data Science Bowl challenge of 2018.

% \miniheadline{Baselines}
\subsection{Baselines}
With exception of \textit{Cellpose (public)}~\cite{stringer2020}, \textit{Harmonic Embeddings}~\cite{kulikov2020}, \textit{PatchPerPix}~\cite{hirsch2020}, and the \textit{Mask R-CNN}~\cite{he2017} and \textit{Stardist}~\cite{schmidt2018} on the  DSB dataset, all other baseline methods are trained by us on the respective dataset.
(In all cases we have used the available code from the original authors.)

Cellpose offers a public model that was trained on a huge and diverse set of training data. 
While this public model performed very well on the DSB data, it performed very poorly on the other two datasets.
We have therefore decided to also train Cellpose on each dataset individually.

% \miniheadline{Data handling}
\subsection{Data Handling}
The BBBC010 dataset consist of only 100 images of $696\times 520$ pixels each.
Like it is commonly done~\cite{novotny2018,hirsch2020,yurchenko2017}, we have randomly split these images in two equally sized sets, one used for training, the other for evaluation.
During training we used 8-fold augmentation of $256\times 256$ patches that we have previously cropped centered around each worm in the data.
We then randomly remove 15\% of all generated crops for validation purposes and average results over 9 independent runs.

For the Usiigaci data we split the 50 images of size $1024\times 1022$ pixels as suggested by Tsai~\etal~\cite{tsai2019} in 45 training and 5 test images.
We train \EmbedSeg using 8-fold augmentation on $512\times 512$ crops that are centered on all objects contained in the data.

The DSB dataset is the largest collection of images, of which we use the same subset as originally suggested in~\cite{schmidt2018}.
It contains a total of $497$ images of variable size and is pre-split in $447$ training and $50$ test images. 
We train on object-centered $256\times 256$ crops. 
For the DSB and Usiigaci datasets, we hold out 15 \% of all training images chosen randomly for validation purposes, prior to cropping, and average results over 9 independent runs.

% \miniheadline{Training details}
\subsection{Training Details}
All results obtained with \EmbedSeg and the method by Neven~\etal~\cite{neven2019} use the ERF-Net~\cite{romera2018} architecture, the Adam optimizer~\cite{kingma2014adam} with a decaying learning rate $\alpha_i = 5 e^{-4}\left[1 - \frac{i}{200}\right]^{0.9}$, where $i$ is the current epoch.
For the BBBC010 data, we use a batch size of $1$, while for both other datasets we employ a batch-size of $2$ and a virtual batch multiplier of $8$, thus giving us an effective batch-size of $16$.
Every training was performed for $200$ epochs, and the model with the best performance \wrt IoU on the validation data is later used for reporting results on the evaluation data (see Table~\ref{tab:results}). The ground truth instance centres are pre-calculated instead of being computed on-the-fly to speeden up the network training. 

% \miniheadline{Performance evaluation}
\subsection{Performance Evaluation}
All results are compared using the Mean Average Precision score ($\text{AP}_{\text{dsb}}$), at IoU thresholds ranging from $0.5$ to $0.9$.
Furthermore, for all \EmbedSeg and Neven~\etal results, we discard objects that are smaller than $37$ pixels.

% \miniheadline{Ablation studies}
\subsection{Ablation Studies}
In order to evaluate the contribution of
$(i)$~using the medoid instead of the centroid in \EmbedSeg, and
$(ii)$~employing test-time augmentation, 
we have performed the respective ablation studies and report the results  on  two datasets (see Table~\ref{tab:ablation}).

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Discussion and Outlook}
\label{sec:discussion}
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
In this work we proposed \EmbedSeg, an adaptation of the well-performing method by Neven~\etal~\cite{neven2019} to the domain of microscopy images.
The unmodified\footnote{Small adaptions of the code by Neven~\etal~\cite{neven2019} are required in order to deal with non-RGB images etc. Still, we consider all such changes `simple' engineering work.} embedding-based method by Neven~\etal shows promising performance on microscopy datasets, outperforming several methods that were developed specifically for this kind of data.
With the modifications we proposed, the performance of \EmbedSeg improves notably, placing mostly first, sometimes second in all experiments we have conducted.
An additional advantage of \EmbedSeg is the small memory footprint on the GPU. 
This can enable users to benefit from this method even on cheap laptop hardware.

While we have only demonstrated \EmbedSeg's performance on 2D data, the approach can easily be applied to 3D datasets.
The compactness of the model is then of particular utility, since a 3D version of some baseline methods would be very slow and require very expensive hardware. 
Hence, in follow-up work we will evaluate \EmbedSeg in the context of 3D microscopy data.


% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\section{Acknowledgments}
%\label{sec:acknowledgments}
\vspace{1em}
\miniheadline{Acknowledgments}
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
{\small
The authors would like to thank Matthias Arzt from CSBD/MPI-CBG for helpful discussions on the presented method and the Scientific Computing Facility at MPI-CBG. 
This work was supported by the German Federal Ministry of Research and Education (BMBF) under the codes 031L0102 (de.NBI) and 01IS18026C (ScaDS2), and the German Research Foundation (DFG) under the code JU3110/1-1(FiSS) and TO563/8-1 (FiSS).
P.T. was supported by the European Regional Development Fund in the IT4Innovations national supercomputing center - path to exascale project, project number CZ.02.1.01/0.0/0.0/16\_013/0001791 within the Operational Programme Research, Development and Education.
}

\end{document}