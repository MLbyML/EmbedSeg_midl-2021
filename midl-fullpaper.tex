\documentclass{midl} % Include author names
%\documentclass[anon]{midl} % Anonymized submission

\usepackage{mwe} % to get dummy images
\jmlrvolume{-- Under Review}
\jmlryear{2021}
\jmlrworkshop{Full Paper -- MIDL 2021 submission}
\editors{Under Review for MIDL 2021}

\title[Embedding-based Instance Segmentation of Microscopy Images]{Embedding-based Instance Segmentation \\of Microscopy Images}

\midlauthor{
\hspace{-0.3em}\Name{Manan Lalit \nametag{$^{1,2}$}} \Email{lalit@mpi-cbg.de}
\AND
\Name{Pavel Tomancak \nametag{$^{2,3}$}} \Email{tomancak@mpi-cbg.de}
 \AND
\Name{Florian Jug \nametag{$^{1,2,4}$}} \Email{jug@mpi-cbg.de} \\
\addr $^{1}$~Center for Systems Biology Dresden (CSBD)\\
\addr $^{2}$~Max Planck Institute of Molecular Cell Biology and Genetics\\
\addr $^{3}$~IT4Innovations, V\v{S}B - Technical University of Ostrava, Ostrava-Poruba, Czech Republic \\
\addr $^{4}$~Fondazione Human Technopole, Milano, Italy}

% Commands...
% --------------------
\newcommand{\EmbedSeg}{\mbox{\textsc{EmbedSeg}}\xspace}
\newcommand{\miniheadline}[1]{\noindent\textbf{#1.}}

\makeatletter
\DeclareRobustCommand\onedot{\futurelet\@let@token\@onedot}
\def\@onedot{\ifx\@let@token.\else.\null\fi\xspace}

\def\eg{\emph{e.g}\onedot} \def\Eg{\emph{E.g}\onedot}
\def\ie{\emph{i.e}\onedot} \def\Ie{\emph{I.e}\onedot}
\def\cf{\emph{c.f}\onedot} \def\Cf{\emph{C.f}\onedot}
\def\etc{\emph{etc}\onedot} \def\vs{\emph{vs}\onedot}
\def\wrt{w.r.t\onedot} 
\def\dof{d.o.f\onedot}
\def\etal{\emph{et~al}\onedot}
\makeatother

\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\begin{document}

\maketitle

\begin{abstract}
Automatic detection and segmentation of objects in microscopy images is important for many medical and biological applications.
In the domain of natural images, and in particular in the context of city street scenes~\cite{Cordts2016Cityscapes}, embedding-based instance segmentation leads to high-quality results.
Inspired by this line of work, we introduce \EmbedSeg, an end-to-end trainable deep learning method based on the work by Neven~\etal~\cite{neven2019}. 
While their approach embeds each pixel to the centroid of its parent object instance, in \EmbedSeg, motivated by the complex shapes of biological objects, we propose to use the medoid instead.
Additionally we also make use of a test-time augmentation scheme~\cite{wang2019}, and show that both suggested modifications improve the instance segmentation performance on 2D microscopy datasets notably.
Next, we extend \EmbedSeg for training on volumetric microscopy datasets. 
We demonstrate that our novel 3D extension, as well, achieves competitive results in comparison to state-of-the-art methods on diverse 3D microscopy datasets.
Furthermore, we also provide two new instance-annotated volumetric datasets for public use in order to bench-mark instance segmentation methods in the future.
Lastly, we show that the overall pipeline has a small enough memory footprint to be used on many CUDA enabled laptop hardware.
Our open-source implementation is available at \url{github.com/juglab/EmbedSeg}.
\end{abstract}

\begin{keywords}
instance segmentation, spatial embeddings, test-time augmentation, deep learning
\end{keywords}

\section{Introduction}

Automated segmentation of microscopy images is of two broad types:~(i)~semantic - where the task is to accurately predict the class (\eg `cell', `nucleus', `membrane', `background`) to which a pixel (voxel) belongs, and~(ii) instance - which involves locating all desired structures of a certain class  in an image, assigning them a unique label or id, and creating a mask that perfectly delineates their shape.

Instance segmentation of structures in microscopy images is essential for multiple purposes: 
for example, in the field of developmental biology, determining surface area and volumes of cells in microscopy images aids calculation of the \textbf{per-cell} forces  exerted by the developing embryo on the outer rigid shell during the process of gastrulation \cite{munster2019}; 
similarities in  object shapes and positions at neighboring time points can be leveraged in a tracking scheme, in order to construct a lineage tree indicating how an organism grows from a few cells to become a multi-cellular organism \cite{tinevez2016};
having accurate instance segmentations can aid registration of individual samples to an atlas. This in turn, allows one to comment on the variability of the population statistics \cite{}, et cetera.

In recent years, Deep Learning (DL) based approaches have proven to be extraordinarily capable of instance segmentation in microscopy data~\cite{moen2019, caicedo2019_v2}.
Such methods can be further grouped into two fundamental approaches: \textit{Top-down} and \textit{bottom-up} methods. 
To give an example, Mask R-CNN~\cite{he2017}, the arguably most prominent top-down method, detects object instances via bounding-boxes, then performs an additional refinement step to produce a pixel-mask from multiple bounding-box detections.
Bottom-up methods, in contrast, are designed such that each pixel makes a prediction of either the object class it belongs to~\cite{ronneberger2015}, and/or the shape of the object instance it is part of~\cite{schmidt2018,neven2019,hirsch2020}. In a second phase, all methods need to consolidate their detections/predictions in order to obtain the final set of object instances.
Mask R-CNN~\cite{he2017} or Stardist~\cite{schmidt2018}, for example, avoid multiple detections of the same object by employing non-maximum suppression on an instance associated confidence score.

Unlike in natural images, where most objects have either a vertical or horizontal orientation, objects visible in microscopy images are arbitrarily aligned with respect to the image axes. Mask R-CNN, employing axis-aligned bounding boxes, tends to miss detections as a consequence. Stardist, while improving upon this shortcoming, assumes a star-convex prior on the individual object shapes and suffers when the star-convex shape assumption is not fulfilled. 

While there are a fair number of DL-based Instance Segmentation Methods for handling 2D microscopy data, methods which directly input volumetric microscopy images are far fewer, and either address the task of  predictions on these volumetric images through a pseudo-3D approach \cite{stringer2020} or suffer from a high GPU memory requirement which makes their usage difficult.

Here we present \EmbedSeg, a variation of the inspiring work by Neven~\etal~\cite{neven2019}, who propose a very compact model for end-to-end instance segmentation in the natural image domain.
This method works such that each pixel predicts its \textit{spatial embedding}, \ie another pixel location in the vicinity of the centroid of the object instance that the respective pixel is part of. 
Additionally, the network learns an instance-specific clustering band-width, later used to cluster embedding pixels into object instances. 
The segmentation mask of an object is defined by all pixels that embedded themselves to the same cluster of embedding pixels.
An additional \textit{seediness score} for each pixel is predicted, indicating how likely it is for the respective pixel, and its associated clustering band-width, to represent one object instance. 
All this can be trained end-to-end to predict highly accurate instance segmentations in natural images of street scenes.

In this work we evaluate how well embedding-based instance segmentation works in the domain of microscopy images.
We first evaluate the method by Neven~\etal~\cite{neven2019} on three well known 2D datasets and show that results are close to the state-of-the-art method for the respective dataset.
We then propose modifications of the method by Neven~\etal and show that they improve the performance notably (see Section~\ref{sec:results} and Table~\ref{tab:results}).
Next, we extend \EmbedSeg for training on volumetric images, and demonstrate that our novel 3D extension achieves competitive results on three volumetric datasets, in comparison to state-of-the-art methods.
Furthermore, we also provide two new instance-annotated volumetric datasets for public use in order to bench-mark instance segmentation methods in the future.
Finally, we provide a memory-efficient open-source implementation of \EmbedSeg and compare its memory footprint to other state-of-the-art methods.

\section{Approach}




% \begin{algorithm2e}
% \caption{Computing Net Activation}
% \label{alg:net}
%  % older versions of algorithm2e have \dontprintsemicolon instead
%  % of the following:
%  %\DontPrintSemicolon
%  % older versions of algorithm2e have \linesnumbered instead of the
%  % following:
%  %\LinesNumbered
% \KwIn{$x_1, \ldots, x_n, w_1, \ldots, w_n$}
% \KwOut{$y$, the net activation}
% $y\leftarrow 0$\;
% \For{$i\leftarrow 1$ \KwTo $n$}{
%   $y \leftarrow y + w_i*x_i$\;
% }
% \end{algorithm2e}

% Acknowledgments---Will not appear in anonymized version
\midlacknowledgments{
The authors would like to thank Matthias Arzt from CSBD/MPI-CBG for helpful discussions on the presented method and the Scientific Computing Facility at MPI-CBG. 
The authors would also like to express their gratitude to Frederike Alwes, Ko Sugawara and Michalis Averof from IGFL, France, for providing the Pahryale 3D dataset.
This work was supported by the German Federal Ministry of Research and Education (BMBF) under the codes 031L0102 (de.NBI) and 01IS18026C (ScaDS2), and the German Research Foundation (DFG) under the code JU3110/1-1(FiSS) and TO563/8-1 (FiSS).
P.T. was supported by the European Regional Development Fund in the IT4Innovations national supercomputing center - path to exascale project, project number CZ.02.1.01/0.0/0.0/16\_013/0001791 within the Operational Programme Research, Development and Education.
}


\bibliography{midl-samplebibliography}


\appendix

\section{Proof of Theorem 1}

This is a boring technical proof of
\begin{equation}\label{eq:example}
\cos^2\theta + \sin^2\theta \equiv 1.
\end{equation}

\section{Proof of Theorem 2}

This is a complete version of a proof sketched in the main text.

\end{document}
